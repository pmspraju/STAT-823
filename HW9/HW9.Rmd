---
title: "HW9 - Multiple Regression"
author: "Madhu Peduri"
date: "`r format(Sys.time(), '%B %e, %Y')`"
output:
  html_document:
    df_print: paged
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    highlight: tango
    number_sections: yes
subparagraph: yes
header-includes: \usepackage{hyperref} \usepackage{framed,xcolor} \definecolor{shadecolor}{rgb}{0.99,
  0.95, 0.9} \renewcommand\arraystretch{1.5} \usepackage[none]{hyphenat} \raggedright
  \usepackage{amsmath, amsthm, amssymb, bm}
---

  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
library(rmarkdown)
library(graphics)
library(ggplot2)
library(MASS)
library(Hmisc)
library(epiDisplay)
library(vcd)
library(mnormt)
library(MASS)
library(car)
library(ggpubr)
library(PairedData)
library(lmtest)
library(xtable)
library(faraway)
library(leaps)
library(psych)
options(digits = 3)
opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

### Problem 1 

```{r}
# Read the data
senic <- read.delim("SENIC.txt", header=FALSE,sep = "")
names(senic) <- c('id','stay','age','inf_risk', 'cul_r','xray_r','beds','med','region','daily_avg','nurses','services')
head(senic)
summary(senic)

# lm for infection risk
lm1 <- lm(stay ~ inf_risk, data=senic)
summary(lm1)

# lm for available facilities
lm2 <- lm(stay ~ services, data=senic)
summary(lm2)

#lm for xray ratio
lm3 <- lm(stay ~ xray_r, data=senic)
summary(lm3)

# lm plots
par(mfrow = c(1,3))
plot(senic$stay ~ senic$inf_risk, cex = 1.5, cex.lab = 1.5, las = 1, cex.main = 1.5, xlab='Infection risk', ylab='average length of stay')
abline(lm1, lwd = 2, col = "red")
plot(senic$stay ~ senic$services, cex = 1.5, cex.lab = 1.5, las = 1, cex.main = 1.5, xlab='Services', ylab='average length of stay')
abline(lm2, lwd = 2, col = "red")
plot(senic$stay ~ senic$xray_r, cex = 1.5, cex.lab = 1.5, las = 1, cex.main = 1.5, xlab='X ray ratio', ylab='average length of stay')
abline(lm3, lwd = 2, col = "red")
```

#### Observation
- If we observe the p-values, we have values < 0.05 for three predictors. This says that the null hypothesis of having coefficients = 0 is rejected and linear relation between predictor and response holds good. This suggest the linearity with confidence (1- pvalue)%. 
- Plots of regression functions also shows the linear relationship provide a good fit for all the three predictors.


### Problem 2

```{r}
#Mean squared error
mse1 <- mean(lm1$residuals^2)
mse2 <- mean(lm2$residuals^2)
mse3 <- mean(lm3$residuals^2)
mse <- c(mse1,mse2,mse3)
r2 <- c(summary(lm1)$r.squared, summary(lm2)$r.squared, summary(lm3)$r.squared)
df <- data.frame(MSE=mse,R2=r2)
row.names(df) <- c('Infection risk','Facilities and Services','Chest X-ray ratio')
df
```

#### Observation
- R-square values are under 0.3 for all the three predictors. This shows that less than 30% of variance in dependent variable is explained by these univariate models.
- For the 'Infection risk' predictor, we have less mean square value and hightest Rsquare, so we can say out of three predictors, 'Infection risk' has the largest reduction in variablity of the average length of stay.

### Problem 3

```{r}
# Residual plots
par(mfrow = c(1, 3))
plot(fitted(lm1), residuals(lm1))
abline(h = 0)
plot(fitted(lm2), abs(residuals(lm2)))
abline(h = 0)
plot(fitted(lm3), abs(residuals(lm3)))
abline(h = 0)

par(mfrow = c(1, 3))
plot(lm1,which=c(1),main='Residuals vs Fitted lm1',caption='')
plot(lm2,which=c(1),main='Residuals vs Fitted lm1',caption='')
plot(lm3,which=c(1),main='Residuals vs Fitted lm1',caption='')

# Linearity of residuals
par(mfrow = c(1, 3))
qqnorm(residuals(lm1), main = "QQ Plot-Infection risk")
qqline(residuals(lm1))
shapiro.test(residuals(lm1))

qqnorm(residuals(lm2), main = "QQ Plot-Services")
qqline(residuals(lm2))
shapiro.test(residuals(lm2))

qqnorm(residuals(lm3), main = "QQ Plot-Xray ratio")
qqline(residuals(lm3))
shapiro.test(residuals(lm3))

# Homoscedasticity 
ncvTest(lm1)
ncvTest(lm2)
ncvTest(lm3)

# Correlation
dwtest(lm1)
dwtest(lm2)
dwtest(lm3)
```

#### Observation
- If we see the residual plots, model with infection risk is better compared to other two. 
- Normality: The p-values of shapiro test are less than the significant value < 0.05. Low p-values reject the null hypothesis of normality and that suggests that residuals are not following normal distribution. However, if we see the Qplots, we can see the normality, but presence of outliers could be the reason behind the poor p-values.
- Homoscedasticity: ncvtest has null hypothesis of constant variance for residuals. We have p-values less than the significant value 0.05. This shows the variance is changing basing on the change in the fitted valus. 
- Correlation: Dwtest has the null hypothesis  that the residuals from a linear regression are uncorrelated. Our test has p-values higher than 0.05 supports the null hypothesis suggesting that dependent and independent variables are not autocorrelated. DW=2 also suggests the no autocorrelation. 

### Problem 4

```{r}
# Halfnormal quantiles to see influencing points
par(mfrow = c(1, 3))
halfnorm(cooks.distance(lm1),main='Infection risk')
halfnorm(cooks.distance(lm2),main='Services')
halfnorm(cooks.distance(lm3),main='Chest Xray')

# Influencing points 
lm1I <- influence.measures(lm1)
which(apply(lm1I$is.inf, 1, any))

# Refit the model without the case 47 and 112
#senic1 <- senic[!(senic$id %in% c(47,112)),]
lm1_r <- lm(stay ~ inf_risk, data=senic, subset=-c(47,112))
str(summary(lm1_r))

# Prediction interval for the old model
senic[c('inf_risk','stay')][c(47,112),]
fitted.values(lm1)[c(47,112)]
newdata <- data.frame(inf_risk = c(6.5,5.9))
pio <-predict(lm1, newdata = newdata, interval = "prediction")
row.names(pio) <- c('47','112')
pio

# Prediction interval for the new model
pi <-predict(lm1_r, newdata = newdata, interval = "prediction")
row.names(pi) <- c('47','112')
pi

# Assumptions of refit model 
shapiro.test(residuals(lm1_r))
ncvTest(lm1_r)
dwtest(lm1_r)
```

#### Observation
- The R2 value has improved from 2.8 to 3 for the refit model. The pr value of refit model is less than the original but not significantly less.
- Original 'Length of stay' values are Y=(19.56, 17.94) if their 'Risk of infection' values are X = (6.5,5.9). Using the refit model, we get the prediction intervals as (8.32, 13.3), (7.97, 12.9) for X respectively. 
- We can say that, original values do not fall under the bounds of the prediction intervals. 
- If we can compare the prediction intervals of original and refit model for 'Infection risk', we can say original model's interval are better than refit model. Removing the points (47,112) did not perform better. 
- However, for refit mode, the assumptions are better than the original model.
- Normality : Refit model has p-value > 0.05 which satifies the null hypothesis of Normal distribution for model's residuals.
- Homoscedasticity : Refit model has p-value > 0.05 which satisfies the null hypothesis of constant variance. Refit model has constant variance between dependent and independent variables.
- Collinearity : We have p-value > 0.05 which satisfies the null hypothesis of uncorrelation. 

### Problem 5

```{r}
y <- "stay"

#regsubsets
x1 <- c('id','log(age)','inf_risk', 'log(cul_r)','log(xray_r)','log(beds)','med','log(region)','log(daily_avg)','log(nurses)','log(services)')

fm <- as.formula(paste(y,paste(x1,collapse="+"),sep="~"))
b <- regsubsets(fm,force.in = 1,data=senic)
rs <- summary(b)
kable(with(rs, cbind(which, rss, adjr2, cp, bic)), digits = 4)

# Model with subset1
x <- c('log(id)','log(age)','inf_risk', 'log(xray_r)','log(region)','log(daily_avg)','log(nurses)','log(services)')
#'id','log(cul_r)','log(beds)','med',

fm <- as.formula(
  paste(y,paste(x,collapse="+"),sep="~")
)
mod <- lm(fm, data=senic, subset=-c(47,112,43,80,52,78,26,81,54))
xtable(summary(mod))
summary(mod)
```

#### Observations 
- We can observe from the regsubsets, we have lowest BIC, Mallow's Cp and high adjusted R2 when features 'cultures performed', 'number of beds' and 'region' are omitted.
- After we remove the features suggested by regsubsets, we use the log transformation to normalize the features that have high values. 
- We remove the influencing points and perform the regression model on the selected set of features. 

### Problem 6

```{r}
# Halfnormal quantiles to see influencing points
halfnorm(cooks.distance(mod),main='Half normal plot')

# Influencing points 
modI <- influence.measures(mod)
which(apply(modI$is.inf, 1, any))

#Correlation
dat0 <- senic[, c('age','inf_risk', 'xray_r','region','daily_avg','nurses','services')]
pairs.panels(dat0)

# Assumptions
shapiro.test(residuals(mod))
ncvTest(mod)
dwtest(mod)

# Residual plots 
par(mfrow = c(1, 2))
plot(mod,which=c(1),main='Residuals vs Fitted',caption='')
influencePlot(mod, id=list(n=3), main='Influence plot')
```

#### Observations
- We can see the influencing points from influencer plot and halfnormal plot. We have removed the points for our model.
- From pair plots, we can see that feature set (daily-average, nurses), (daily-average, services), (nurses, services) has a positive correlation. 
- Normality: We have p-value(=0.5)  > 0.05 significant value suggesting a normal distribution for the residuals of our final model.
- Homoscedasticity: We have p-value(=0.8) > 0.05 suggesting a constant variance between dependent and independent variables.
- Collinearity: We have p-value(=0.3) > 0.05 significant value suggesting uncorrelation between dependent and independent variables. 

### Problem 7

- We have a dataset which has below sets of features and the target label that will be predicted.
- Features:
  - Id number
  - Age
  - Infection risk
  - Routine culturing ratio
  - Routine Chest x-ray ratio
  - Number of beds
  - Medical shcool afflication
  - Geographic region
  - Average daily census
  - Number of nurses
  - Available facilities and services. 
- Target:
  - Length of Stay
- We created a model with the features and tested for normality, Constant variance and collinearity and found our assumptions were less than significant values and tests were negative.
- For a better prediction model, our assumptions should be positive. We call difference between fitted values and actual values target variables as residuals. A better prediction model should hae residuals forllow normality, constant variance and uncorrelated.
- We used halfnormal test and determined the influencing points and built our prediction model with subset of data by omitting the influencing points.
- We observed few features are high in scale compared to others. Used log transformation to normalize the out of scale features.
- We used regsubsets method to determine the best set of variables for our model. We used parameters BIC, Mallow's Cp and adjusted R2 to determine the best set of variables out of the given set. Below are the best set of features with lowest BIC, Cp and highest adjusted R2. 
- Best set of features:
  - age
  - inf_risk
  - xray_r
  - region
  - daily_avg
  - nurses
  - services
- By using above set of variables, we get the Adjusted R2 = 0.64 and assumptions normality, constant variance and Collinearity are tested positive.

## Document Information.

All of the statistical analyses in this document will be performed using `r R.version.string`.  R packages used will be maintained using the [packrat](http://rstudio.github.io/packrat/) dependency management system.  

```{r session-info}
sessionInfo()
```
